{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEOOMsh2flPPxkbp5341Er",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijayashree23/PRODIGY_GA_03/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mASstmu_7TGi",
        "outputId": "95e22a42-a8c0-456b-db46-596e1f72112f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there lived not long since one of those gentlemen that keep a lance in the lance-rack, an old buckler, a lean hack, and a pigeon or so extra on Sundays, made away with three-quarters of his income.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Sample text data (you can replace this with any text)\n",
        "text_data = \"\"\"\n",
        "In a village of La Mancha, the name of which I have no desire to call to mind, there lived not long since one of those gentlemen that keep a lance in the lance-rack, an old buckler, a lean hack, and a greyhound for coursing. An olla of rather more beef than mutton, a salad on most nights, scraps on Saturdays, lentils on Fridays, and a pigeon or so extra on Sundays, made away with three-quarters of his income.\n",
        "\"\"\"\n",
        "\n",
        "# Function to build the Markov chain model\n",
        "def build_markov_model(text, n_gram=1):\n",
        "    model = {}\n",
        "    words = text.split()\n",
        "\n",
        "    for i in range(len(words) - n_gram):\n",
        "        key = tuple(words[i:i+n_gram])\n",
        "        next_word = words[i+n_gram]\n",
        "\n",
        "        if key not in model:\n",
        "            model[key] = []\n",
        "        model[key].append(next_word)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to generate text using the Markov chain model\n",
        "def generate_text(model, n_gram=1, max_length=100):\n",
        "    key = random.choice(list(model.keys()))\n",
        "    generated_text = list(key)\n",
        "\n",
        "    for _ in range(max_length - n_gram):\n",
        "        next_word = random.choice(model[key])\n",
        "        generated_text.append(next_word)\n",
        "\n",
        "        key = tuple(generated_text[-n_gram:])\n",
        "        if key not in model:\n",
        "            break\n",
        "\n",
        "    return ' '.join(generated_text)\n",
        "\n",
        "# Build the Markov chain model\n",
        "n_gram = 2  # You can change this to 1, 2, 3, etc.\n",
        "markov_model = build_markov_model(text_data, n_gram)\n",
        "\n",
        "# Generate text using the Markov chain model\n",
        "generated_text = generate_text(markov_model, n_gram, max_length=50)\n",
        "print(generated_text)\n"
      ]
    }
  ]
}